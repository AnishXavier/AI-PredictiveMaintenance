# Solution Template Architecture for PdM

PdM solution deployments are observed in three forms:

- _On Prem_ - for scenarios where customers do not want to connect to the cloud, but with the data delivered via local, private networks to central, on-prem servers where modeling and analytics are done.
- _Cloud based_ - for scenarios where devices are managed from the cloud for infinite scale, with the AI and analytics processing centralized in the cloud based on data delivered via the Internet. The models are managed from a central repository, and model operationalization is also in the cloud.
- _Edge based_ - This is a variant of the cloud scenario, where modeling is done centrally in the cloud, but the models aredelivered to edge devices that cannot be connected to the cloud.

This solution template implements a _cloud based_ architecture. Large scale production AI applications with CICD (continuous integration continous deployment) are composed of two parts in general, operating in a virtous cycle:
- an _inner AI loop_ that involves data preparation, iterative model training and testing, and model deployment for scoring new data; and
- and an _outer processing loop_ that plays the equally important role of enabling data ingestion, staging on the input, and enabling post-scoring analytics, publishing, and presentation of results - at scale, with the enterprise requirements of  availability, security, manageability etc.

This template demonstrates how to build an end to end POC solution composed of these two parts. 

![PdM_Solution_Template](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/docs/img/PdM_Solution_Template.png)

The system works as follows - going left to right:
- INGEST: <span style="color:blue">[1]</span> Multiple streams of sensor data, each generated by a general purpose [Sensor Data Simulator](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/WebApp/App_Data/jobs/continuous/Simulator/simulator.py) are ingested into an [Azure IoT Hub](https://azure.microsoft.com/en-us/services/iot-hub/). Each stream represents data for one specific measurement - such as temperature, pressure etc.- from one particular device. You can configure multiple devices, each with multiple sensors. <span style="color:blue">[2]</span> Maintenance logs, error logs, failure history etc. are ingested into Azure Blobs.
- STAGE: <span style="color:blue">[3]</span> The data from IoTHub is sent as-is for storage in multiple files in the Azure Blob.
- PREPARE: Data preparation is done in combination with feature engineering as part of the next step.
- TRAIN: <span style="color:blue">[4]</span> For model training, PySpark code is executed in two Jupyter Notebooks: [FeatureEngineering.ipynb](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/AML/Notebooks/FeatureEngineering.ipynb) and [ModelTraining.ipynb](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/AML/Notebooks/ModelTraining.ipynb).
  - To enable model training at scale, the template is set up such that you can invoke the creation of Spark clusters on Azure Batch service. These notebooks are copied to the Spark cluster nodes.
  - As you read the documentation and run the individual sections of the [feature engineering](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/AML/Notebooks/FeatureEngineering.ipynb) notebook, the PySpark code reads the staged data in Azure Blob files, joins them together to an appropriate schema, and prepares the features and labelled data for training and test in Python dataframes.
  - As you read the documentation and run the individual sections of the [model training](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/AML/Notebooks/ModelTraining.ipynb) notebook, the code builds a predictive decision tree or random forest model, and stores the model as a pickle file in Azure Blobs.
  - This model is registered in Azure ML v2.0 model management service.
- TEST: The model is tested using the code in [Operationalization.ipynb](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/AML/Notebooks/Operationalization.ipynb). The TRAIN-TEST stages can be an experimental, iterative loop between training the model using a training data set, and testing it with a test data set, until a model of acceptable accuracy is built. <span style="color:blue">[5]</span> The model(s) are registered in Azure Model Management service - so that multiple versions of the model with their specific data preparations are available for deployment.
- DEPLOY: <span style="color:blue">[6]</span> The candidate model is then deployed using Azure ML deployment services for _online scoring_ of one or few records at a time. The [scoring engine](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/WebApp/App_Data/jobs/continuous/Scorer/scorer.py) is deployed as a web service in a Docker container, along with another dispatcher web service in another Docker container, to an Azure Kubernetes cluster <span style="color:blue">[7]</span>. The scoring engine code does the same feature engineering steps on new data as done for the TEST stage, to ensure consistency.
- SCORE: New data is fed from IoTHub into a Service Bus which serves as a buffer to ensure lossless message output from IoTHub, and as a queue for the output. The dispatcher web service pulls messages from the service <span style="color:blue">[8]</span>, and computes the score from the scoring engine.
- PUBLISH: The scored output is stored in an Azure Table <span style="color:blue">[9]</span> for further processing and visualization.
- CONSUME: <span style="color:blue">[10]</span> The scored results can be viewed via PowerBI or other analytics tools (TBD - implementation pending)

The grayed out section of the architecture shows a placeholder for batch scoring, which will also be supported for public preview.

# Solution Template Design Notes
This section provides the design internals of the solution template, so that:
- you can understand how each component is provisioned, and its role in the architecture
- you can customize or replace a particular component - once it has been deployed in the resource group - from the [Azure portal](http://portal.azure.com)
- (FUTURE) you can fork this code to author a custom solution template for your customer.

We will list the key design items in teh archtiecture and explain teh reasons behind the choice of the component and/or the design.

## Resource Provisioning
- All the resources that are provisioned in a resource group as a result of the deployment are specified in a [Manifest.xml](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/core/Manifest.xml). This file is read by the Microsoft-internal deployment engine that proceeds to set up the resources in the resource group in the following sequence.
- Create Azure Batch account - [azureBatch.json](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/core/arm/azureBatch.json). The Azure Batch service helps run large training jobs on a cluster. It is also very elastic - you can deploy a Spark cluster (or any other cluster like HDInsight) on Azure Batch, and quickly release the resources as soon as you are finished with it.
- Create an AAD application to enable the user to interact with AML model management. We needed to secure the application with AAD so that only authorized users can view the dashboard and start and stop the clusters (<span style="color:red">ToDo - Pointer to the code</span>)
- Create the IOT Hub - [iotHub.json](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/core/arm/iotHub.json). The solution template demonstrates the ingestion of real-time data from sensors and uses IOT hub to store it in Blob for training. 
- Create AML Model Management account - [modelManagement.json](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/core/arm/modelManagement.json). The solution template demonstrates the use of Azure ML v2.0 for for model management and operationalization. Model management is especially useful for data science teams where 10’s of models would be created in a month/week or even days (Uber, Amazon, Walmart)
  - Azure ML v2.0 support model operationalization – we chose to demonstrate this for online (wrongly called “real-time” in most docs) model scoring (as in churn prediction, anomaly detection or other online scenarios)
  - Azure ML v2.0 supports this operationalization via web services implemented in Docker containers – which are deployed for scale on Azure Kubernetes clusters. This again, is the standard pattern that we have seen success in ADS customer engagements
- Create service bus account and create a service bus queue [serviceBus.json](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/core/arm/serviceBus.json) 
- Create the demo dashboard (Flask web application), data generator (web job), and scoring orchestrator (web job) - [demoDashboard.json](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/core/arm/demoDashboard.json). The flask web app provides an easy interface for the users to view and change data generation from devices, allow users to start and stop the spark cluster and make it easier for creating a web service once a model is trained. 
- Data generation is done in web jobs and they can be stopped easily from the Azure Portal, by following this web click funnel: Azure Portal -> PDM resource group -> App Service -> Select Webjobs -> (Simulator)
- The Scoring Orchestrator is also available in the above link. Webjobs->(Scorer)
- Link the AAD application to the demo dashboard [authSettings.json](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/core/arm/authSettings.json) 
- Configure IOT Hub to write output to storage [iotHubStorageRoute.json](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/core/arm/iotHubStorageRoute.json). Data from IOT hub is routed to store into Azure Storage Blob. The data in blob is used by the training notebook to train the model.
- Create the ACS Kubernetes scoring cluster - https://github.com/Azure/AI-PredictiveMaintenance/blob/master/core/arm/operationalization.json

## Model Training
- Start a data flow
  - Login into the [PDM dashboard] (ToDo - link to code) by clicking on the successful deployment link
  - Context: Our abstract machine contains 10 sensors: speed, temperature, ambient temperature, pressure, ambient pressure, vibration
  - Click on Telemetry(code link) and click on Creating Devices. Ensure that the devices show Connected in the connection status. If not, go to Azure portal Web job and restart the Simulator.
  - Start the data generator – Create data to create labels and train the model (default is 10 machines, but the user can add up to a total of 200 machines)
  - The actual data generator is implemented as a web job with all the code in [Simulator folder](https://github.com/Azure/AI-PredictiveMaintenance/tree/master/src/WebApp/App_Data/jobs/continuous/Simulator)
  - IOT Hub receives the data from the generator and stores it as blobs (in avro format) in the storage account (Azure Portal->Pdm Resource Group-> Storage Accnt->Blob Service->telemetry….)
  - The user need to run the data generator for 5 minutes to create enough data for training. (We can probably provide guidance on when to stop the data generation).
- Create the training cluster
  - Navigate to the PDM dashboard
  - Under “Analytics” click “create cluster"
  - This uses AZTK (Azure Distributed Data Engineering Toolkit) to create an Azure Batch cluster running Spark. The cluster size is configurable, options presented are 1, 2, 3, 5. (ToDo - Code links)
  - The details of the cluster are abstracted to the user.  We could use DSVM here for smaller training datasets.  We should switch to the AML training cluster when it’s ready.
  - Training – Train the model
- Once the training cluster is created, it will provide an ssh command to tunnel to master node of the cluster. One the tunnel is established, open any browser and enter localhost:8888. The browser will display the notebooks. Follow steps below:
  - Featurize the training data - https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/AML/Notebooks/FeatureEngineering.ipynb
  - Train the model - https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/AML/Notebooks/ModelTraining.ipynb
  - TODO – Maintenance records are being added in TASK 141985.  As of 2018/04/17 the maintenance records are hardcoded in ModelTraining.ipynb:In[5].
- Operationalize {operationalization.ipynb](https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/AML/Notebooks/Operationalization.ipynb)
  - Create score.py, initialize, and run the model on the 3 records from service_schema.json (sanity check)
- [Optional but recommended] Delete the training cluster via the demo dashboard.

- Operationalization
- Model Management 
  - Register Model – https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/WebApp/flask/app.py#L316 
  - The operationalization tab in the demo dashboard enabled the user to register the model with AML Model Management.
  - https://docs.microsoft.com/en-us/azure/machine-learning/preview/model-management-cli-reference 
  - https://docs.microsoft.com/en-us/azure/machine-learning/preview/model-management-api-reference 
- Register Manifest–  https://github.com/Azure/AI-PredictiveMaintenance/blob/master/src/WebApp/flask/app.py#L336 
- Create a manifest record and associate it with assets:
  - score.py
  - service_schema.json
- Specify the targetRuntime – SparkPython (used in PdM) or Python (if Spark is not needed)
- Create Image – Create a docker image to operationalize the model
- Create Service – Deploy the docker image into the Kubernetes cluster, return a scoring URL and API key
- Consume Service – Take the scoring URL and API key from the create service step and register them with the scoring orchestrator.
- Start the data flow for realtime scoring.
  - Data Generator – Start the data generator to send messages to IOT Hub
  - IOT Hub – Ingest data from the generator and route it to ServiceBus
  - The scorer web job (scoring orchestrator) pulls messages from the ServiceBus queue, call the ACS web service for scoring, and persist predictions to the Predictions table. The prediction table is present in Azure Table and can be viewed using Storage explorer.
- (In progress – ETA 2018/04/27) Visualization – Present the output to the user

Additional inputs

Customer Flow (revised): This will require changing the existing step by step process explained in Readme.md with screen captures
Customer visits the Github link and clicks on the Deploy to Azure link. The link lands up on the Azure page where the customer is asked for  some key inputs. Once customer clicks the create button, the PDM solution is deployed into a resource group. As soon as the deployment completes the user is provided a link to Dashboard.
- Customer clicks on dashboard, accepts the AAD (first time) authorization and then displays the Flask application which lands on Home Page(We need to add material here. Today it’s empty. We probably can provide the next steps one can take and also instructions on starting and stopping the cluster and operationalizing a model)
- Customer needs to click on Telemetry and click create devices as the first step. (Ram please note here)
Once devices are created it takes time to start them up(Need to confirm with Andrew if this is by design or happens sometimes). If not started , customer can go to the Portal and restart the Simulator web job located in the App service of the resource group.
- Once customer sets up devices, she needs to go to Analytics Page(Need to change the heading) . Customer needs to select machines( Can we provide some guidance to customer on how to select) and the number of machines and click create cluster. Once cluster is created then customer is instructed to tunnel to the cluster so that notebooks can be viewed.
- Remaining process remains same for running notebooks and then coming back to portal for deploying a new model.