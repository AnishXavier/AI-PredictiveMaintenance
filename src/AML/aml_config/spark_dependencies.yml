# Spark configuration and packages specification. The dependencies defined in
# this file will be automatically provisioned for runs that use Spark.

# For managing third-party python libraries, see conda_dependencies.yml.

# Spark configuration properties.
configuration:
  "spark.app.name": "Azure ML Experiment"
  "spark.driver.memory":	"6g"
  "spark.executor.memory":	"6g"
  "spark.yarn.maxAppAttempts": 1

# Repositories to search for the specified Spark packages.
repositories:
  - "https://mmlspark.azureedge.net/maven"

# Spark packages to include in the run.
packages:
  - group: "com.databricks"
    artifact: "spark-avro_2.11"
    version: "4.0.0"
